%% LyX 2.1.3 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[english]{article}
\renewcommand{\familydefault}{\sfdefault}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage{geometry}
\geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
\setlength{\parskip}{\medskipamount}
\setlength{\parindent}{0pt}
\usepackage{amssymb}

\makeatletter
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\usepackage{amsmath}
\date{}

\makeatother

\usepackage{babel}
\begin{document}

\title{Small Problem 1: Bayesian Linear Regression}

\maketitle
\vspace{-0.5in}


\section*{Summary}


\subsection*{Given:}

A set of training points $\left\{ \left(x_{i},y_{i}\right)\right\} _{i=1}^{N}$,
where $x_{i}\in\mathbb{R}^{d}$ and $y_{i}\in\mathbb{R}$

Generative model for the data in terms of the weight vector $w$ and
hyperparameters, as described below.


\subsection*{Find:}

Query 1: The posterior probability distribution of $w$.


\subsection*{Metrics:}

Metric 1: Expected squared Euclidean distance between the predicted
mean $\hat{w}$ and the true mean $w$, where the expectation is taken
with respect to the posterior distribution.

Metric 2: Total variation distance between the computed posterior
and the correct posterior over $w$.


\section*{Details:}

The file ``problem-1-generator.R'' contains R code to generate the
true regression coefficients and the input training data. The model
is 
\begin{eqnarray*}
\Sigma_{1} & = & 2\mathbf{I}_{5\times5}\\
\mu & \sim & \mathcal{N}\left(0,\Sigma_{1}\right)\\
\Sigma_{2} & = & \mathbf{I}_{5\times5}\\
\Sigma_{\mbox{prior}} & \sim & \mbox{Wishart}\left(1,\Sigma_{2}\right)\\
w & \sim & \mathcal{N}\left(\mu,\Sigma_{\mbox{prior}}^{-1}\right)\\
x_{ij} & \sim & \mbox{Uniform}\left(-1,1\right)\\
\tau & \sim & \mbox{Gamma}\left(0.5,2\right)\\
\epsilon_{i} & \sim & \mathcal{N}\left(0,\frac{1}{\tau}\right)\\
y_{i} & = & \sum_{j}x_{ij}w_{j}+\epsilon_{i}
\end{eqnarray*}


The file contains 500 training examples generated from a single run
of the R code. There are four covariates generated uniformly from
$\left[-1,1\right]$. The values of the variables that generated the
data are
\begin{eqnarray*}
\mu & = & (-1.8195312,1.2237587,0.8361809,-2.6017006,-2.3574193)\\
\Sigma_{\mbox{prior}} & = & \mbox{(see ``problem-1-prior.Sigma.csv'')}\\
w & = & (-1.731855,2.986017,2.698284,-3.591651,-3.714157)\\
\left(x_{i},y_{i}\right) & = & \mbox{(see ``problem-1-data.csv'')}
\end{eqnarray*}


Queries/Metrics: 
\begin{enumerate}
\item Let $P\left(\hat{w}|D\right)$ be the posterior distribution of the
estimated weight vector. One metric is the expected squared error
$\mathbb{E}\left[\left\Vert \hat{w}-w\right\Vert ^{2}\right]$ under
this distribution.
\item We have provided samples generated from the true posterior distribution
$P_{\mbox{true}}\left(\hat{w}|D\right)$. We can estimate the total
variation distance between the true distribution and your estimate
$P\left(\hat{w}|D\right)$ using the samples generated by your estimated
distribution: 
\[
\int_{w}\left|P\left(\hat{w}|D\right)-P_{\mbox{true}}\left(\hat{w}|D\right)\right|dw
\]
\end{enumerate}

\subsection*{Submission:}
The metric value should be computed for each elapsed time step (by calling the provided code or by implementing yourself). The metric value should be reported for several elapsed time steps. The number of elapsed time steps should be sufficient to establish an ``informative profile".


For further details regarding submission of the metric and your code, please refer to the main CP4 problem description document, e.g. PPAML-Challenge-Problem-4.pdf.


Sample output for this problem has been provided in the ``sampleoutput" folder:

problem-1-query-1-metric-1.csv\\
problem-1-query-1-metric-2.csv


\end{document}
